#!/usr/bin/env python3

"""
Makes a request to the Github API and compares
the list of repos from the API to cached information
"""

import os
import sys
import json
import time
from typing import List, Dict, Set, Any, Tuple
from pathlib import Path

Json = Any
RepoDB = Dict[str, Json]

try:
    import toml
    import requests
    import click
    import vimbuffer
except ImportError as e:
    print(str(e), file=sys.stderr)
    raise SystemExit(1)

this_dir: Path = Path(__file__).absolute().parent
cachefile: Path = this_dir / "cache.json"
datafile: Path = this_dir / "data.toml"
github_username: str = "seanbreckenridge"


def cached_response_has_expired() -> bool:
    """
    Returns T/F which determines whether or not
    to download fresh data from Github API
    """
    if not cachefile.exists():
        print("Cache file doesn't exist...", file=sys.stderr)
        return True
    if time.time() - cachefile.stat().st_mtime > 60 * 60 * 6:
        print("Cache file has expired, re-downloading...", file=sys.stderr)
        return True
    else:
        print("Using cached data...", file=sys.stderr)
        return False


# downloads new repository data if needed,
# returns the parsed JSON data
def get_repository_data(unowned_r: List[str]) -> List[Json]:
    if not cached_response_has_expired():
        try:
            return json.loads(cachefile.read_text())
        except json.decoder.JSONDecodeError:
            print("Failed to load JSON from cache file...", file=sys.stderr)
    print(
        f"Downloading repository information for {github_username}...",
        file=sys.stderr,
    )
    # loop through the paginated responses to get all repos
    repo_info = []
    page: int = 1
    while True:
        url = f"https://api.github.com/users/{github_username}/repos?page={page}"
        print(f"Requesting {url}", file=sys.stderr)
        resp = requests.get(
            url,
            headers={"Accept": "application/vnd.github.full+json"},
        )
        resp.raise_for_status()
        resp_json = resp.json()
        if resp_json:
            repo_info.extend(resp_json)
        else:
            break
        page += 1
    for other_repo in unowned_r:
        url = f"https://api.github.com/repos/{other_repo}"
        print(f"Requesting {url}", file=sys.stderr)
        resp = requests.get(
            url,
            headers={"Accept": "application/vnd.github.full+json"},
        )
        resp.raise_for_status()
        repo_info.append(resp.json())
    with cachefile.open("w") as jf:
        json.dump(repo_info, jf)
    return repo_info


# return all data from the data.toml file
def load_data() -> Tuple[Set[str], RepoDB]:
    repos: Dict[str, Json] = {}
    ignored: Set[str] = set()
    if not datafile.exists():
        return ignored, repos
    with datafile.open("r") as df:
        data = toml.load(df)
    for key, val in data.items():
        if key == "ignored":
            ignored = set(val)
        else:
            repos[key] = val
    return ignored, repos


# if any of the items in repos in the loaded data aren't owned by me
# return a the full_name of those so they can be requested individually
# this part is manually entered into the toml file
def unowned(repo_data: RepoDB) -> List[str]:
    unowned_repos: List[str] = []
    for repo in repo_data:
        if not repo.startswith(github_username):
            unowned_repos.append(repo)
    return unowned_repos


# priority:
# 1: put at bottom
# 2: order by star
# 3: at the top
#
# score:
# acts as a buffer for stars
# if I want something to appear slightly higher up
# when calculating order on priority 2, it compares
# score + stars

# prompt me to add any new items
def prompt_new(repo_info: List[Json], repo_data: RepoDB, ignored: Set[str]) -> RepoDB:
    prompted: int = 0
    for repo in repo_info:
        rname: str = repo["full_name"]
        if not repo["private"] and rname not in ignored:
            if rname in repo_data:
                repo_data[rname]["updated_at"] = repo["updated_at"]
                repo_data[rname]["stars"] = repo["stargazers_count"]
            else:
                # if running in the background to update star/updated at
                # metadata, don't prompt me
                if "PROJECTS_BG_UPDATE" in os.environ:
                    continue
                prompted += 1
                if not click.confirm("Ignore '{}'?".format(rname)):
                    repo_desc: str = vimbuffer.buffer(
                        string=repo["description"]
                    ).strip()
                    new_repo_data = {
                        "name": repo["name"],
                        "full_name": repo["full_name"],
                        "html_url": repo["html_url"],
                        "description": repo_desc,
                        "updated_at": repo["updated_at"],
                        "stars": repo["stargazers_count"],
                        "language": repo["language"],
                        "has_gitlab": True,
                        "priority": 2,
                        "score": 0,
                    }
                    if click.confirm("Remove GitLab?"):
                        new_repo_data["has_gitlab"] = False
                    if click.confirm("Add URL?"):
                        new_repo_data["url"] = click.prompt("URL ")
                    repo_data[rname] = new_repo_data
                else:
                    ignored.add(rname)

        # exit once we've done 5, can re-run to continue adding
        # so I can take breaks
        if prompted >= 5:
            break
    repo_data["ignored"] = sorted(list(ignored))
    return repo_data


def main():
    ignored, repo_data = load_data()
    unowned_repos: List[str] = unowned(repo_data)
    repo_info: List[Dict] = get_repository_data(unowned_repos)
    repo_data = prompt_new(repo_info, repo_data, ignored)
    with datafile.open("w") as tf:
        toml.dump(repo_data, tf)


if __name__ == "__main__":
    main()
